What's the difference between speaking and singing? It’s a harder question than it sounds. You may think the answer is simply that songs have melodies and that speech lacks them. But that doesn’t account for manyxamples of rap and laments (musical traditions that combine singing and weeping), for instance. Or maybe you think songs are defined by a [regular beat](https://www.scientificamerican.com/article/why-some-songs-makes-everyone-want-to-dance/). Plenty of songs don't have one, however: think Gregorian chants or the improvisational *alaps* that open northern Indian ragas or even [Pink Floyd’s](https://www.scientificamerican.com/article/neuroscientists-re-create-pink-floyd-song-from-listeners-brain-activity/) experimental prog-rock song “Interstellar Overdrive.”

Defining music “does seem intuitive,” says Patrick Savage, a comparative musicologist at the University of Auckland in New Zealand. “And yet when you try to define it, you can almost always find some kind of counterexample.”

In a study published on Wednesday in *Science Advances,* Savage and an international group of collaborators set out to understand how traditional songs differ from speech around the globe. Traditional music can include [folk songs](https://www.scientificamerican.com/podcast/episode/researchers-analyzed-folk-music-like-it-was-mutating-dna-they-found-amazing-parallels-between-life-and-art/), lullabies, religious music and more. By analyzing song and speech samples from 75 people representing various cultures around the world, they discovered that traditional songs generally tend to be slower and higher-pitched and to have more stable pitches overall than spoken language. While these rules still have exceptions, they reveal hidden commonalities that could hint at how what we think of as “music” evolved in the first place.

## On supporting science journalism
If you're enjoying this article, consider supporting our award-winning journalism by [subscribing](/getsciam/). By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.

“We can find something we can call music in every society,” says the study’s lead author Yuto Ozaki, who studies cross-cultural diversity in music at Keio University in Tokyo. The same is true of spoken language, and the differences and similarities between these traditions can help researchers understand how music came to be. Prior to the new study, Savage and other scientists had found a [handful of acoustic features](https://www.pnas.org/doi/10.1073/pnas.1414495112) that most musical traditions have in common—so-called statistical universals. What we think of as “songs,” for instance, tend to use short phrases and specific pitches.

But researchers couldn’t be certain such features were actually unique to music; they could have also been present in spoken languages. Short phrases, for example, can occur in both forms of vocalization because “we only have so much breath we can use at one time,” Savage explains. And while songs do often use specific pitches, tonal languages such as Mandarin Chinese rely heavily on pitch to differentiate between words in spoken language, too.

So Savage and Ozaki set out to compare song and speech worldwide. Although collections of music samples from around the world certainly exist, many of these recordings are what Savage calls “disembodied artifacts” that lack cultural and linguistic context. And he notes that many were made without the meaningful involvement of the people who were studied.

To get data with deeper cultural context, Savage and Ozaki recruited 75 music researchers from around the world as collaborators. Each submitted recordings in which they performed a traditional tune from their culture. This was a “gigantic sample,” says Robert Zatorre, a neuroscientist studying speech and song at McGill University, who was not involved in the new study. Every populated continent and most regions of the world were represented. For his own recording, Savage chose to sing “Scarborough Faire.” Ozaki sang a traditional tune from the Tokyo region called “Omori Jinku.”

![Study co-authors Gakuto Chiba of Japan (left), Neddiel Elcie Muñoz Millalonco of Chile (middle) and Latyr Sy of Senegal (right) sing and play traditional stringed instruments and drums](https://static.scientificamerican.com/dam/m/73f413c3abe000a5/original/FOLK-MUSIC-COMP-WEB.jpg?w=900)
Study co-authors Gakuto Chiba of Japan (left), Neddiel Elcie Muñoz Millalonco of Chile (middle) and Latyr Sy of Senegal (right) sing and play their traditional instruments.

Latyr Sy, Gakuto Chiba, Neddiel Elcie Muñoz Millalonco, Aleksandar Arabadjiev

“There's this really great [saying]: ‘Nothing about me without me,’” says co-author Diana Hereld, a clinical neuropsychologist studying music at University of California, Los Angeles, who represented Cherokee musical tradition in the study. “So as opposed to a bunch of musicologists in our ivory towers sharing our opinions with the world, this [study involved] people who speak the languages that they’re writing about.”

To check whether this unusual experimental setup biased the results, only some of the researchers were aware of the hypotheses ahead of time, and the team reran their analyses excluding the data from those who knew the hypotheses to confirm that information did not impact the overall results. The team also preregistered its experimental design with the journal that published their study ahead of time—an increasingly common research choice that helps ensure scientific integrity.

Each co-author generated four samples of their chosen traditional tune. In one recording, they played an instrumental version of the song. In another, they sang the melody. In a third, they spoke the lyrics. The final recording was a sample of natural speech in the form of a description of the song. The data showed that the instrumental melodies had the slowest tempos and the highest and most stable pitches while the examples of natural speech had the fastest tempos and the lowest and least stable pitches. The sung melodies and recited lyrics both fell on a continuum in between these two extremes.

“What’s remarkable is that despite those huge [cultural] differences, there’s something that’s in common,” Zatorre says. These commonalities provide hints for how music might have evolved. Here, there are a few competing theories. Some researchers have hypothesized that music arose as a simple by-product of speech. Others have suggested that, like birdsong, it stemmed from sexual selection. And a third idea is that music and singing evolved because they fulfilled some sort of social function.

These results “suggest that [music] is not just a by-product of speech,” Savage says. “There’s *something* causing them to be consistently different in all these different cultures.” But what that X factor might be is pure speculation. Savage and Ozaki suggest singing might have evolved to [bring groups of people close together](https://www.scientificamerican.com/article/music-synchronizes-the-brains-of-performers-and-their-audience/)—an idea called the social bonding hypothesis.

“Slower, more regular and more predictable melodies [may] allow us to synchronize and to harmonize and, through that, to bring us together in a way that language can’t,” Savage says.

Such a hypothesis is very challenging to prove, Zatorre says, but it makes sense that singing would have evolved to fulfill a social, communicative function just like language did. “Music can be quite powerful” when it comes communicating emotion, he says. “And in that regard, it can be much more effective than speaking.”
